{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Vhb8ylJIHLoJLDdYKBZQP8BaCh_D8zvY",
      "authorship_tag": "ABX9TyNHE3NgiTgA9Y2ThCGWqutX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wfvh/gan/blob/main/GAN_224pixels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM7A5S7TkNyg"
      },
      "source": [
        "import pathlib\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import imageio\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def make_generator_model(noise_dim, img_width, img_height):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape=(noise_dim,)))\n",
        "\n",
        "    model.add(layers.Dense(7*7*512, use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 512)))\n",
        "    assert model.output_shape == (None, 7, 7, 512)  # Note: None is the batch size\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(512, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 512)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 28, 28, 256)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 56, 56, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 112, 112, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, img_width, img_height, 3) #224,224,3\n",
        "\n",
        "    return model\n",
        "def make_discriminator_model(img_width, img_height):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(layers.InputLayer(input_shape=(img_height, img_width, 3)))\n",
        "    model.add(layers.GaussianDropout(0.05))\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1)) # no activation. logits=true when training\n",
        "    return model\n",
        "\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = wasserstein_generator_loss(fake_output)\n",
        "      disc_loss = wasserstein_discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "def train(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "        for batch_of_images in dataset:\n",
        "            train_step(batch_of_images)\n",
        "        end = time.time()\n",
        "        print ('Time for epoch {} is {} sec'.format(epoch + 1, round(end-start, 3)))\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "    # Notice `training` is set to False.\n",
        "    # This is so all layers run in inference mode (batchnorm).\n",
        "    time1 = time.time()\n",
        "    predictions = model(test_input, training=False)\n",
        "    fig123 = plt.figure()\n",
        "    time2 = time.time()\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        ax1 = fig123.add_subplot(1, 1, i+1)\n",
        "        image = tf.cast(tf.math.round(predictions[i, :, :, :] * 127.5 + 127.5), tf.int32)\n",
        "        ax1.imshow(image)\n",
        "        plt.axis('off')\n",
        "    time3 = time.time()\n",
        "\n",
        "    canvas = plt.get_current_fig_manager().canvas\n",
        "    canvas.draw()\n",
        "    pil_image = PIL.Image.frombytes('RGB', canvas.get_width_height(), canvas.tostring_rgb())\n",
        "    pil_image.save('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.close()\n",
        "    #print(\"###Time for saving images {}, {}, {}\".format(round(time2-time1,3), round(time3-time2,3), round(time.time()-time3,3)))\n",
        "def generate_image():\n",
        "\n",
        "    generated_image = tf.cast(tf.math.round(generator(tf.random.uniform([1, noise_dim]), training=False) * 127.5 + 127.5), tf.int32)[0]\n",
        "\n",
        "    plt.imshow(generated_image)\n",
        "    plt.axis('off')\n",
        "    canvas = plt.get_current_fig_manager().canvas\n",
        "    canvas.draw()\n",
        "    pil_image = PIL.Image.frombytes('RGB', canvas.get_width_height(), canvas.tostring_rgb())\n",
        "    pil_image.save(\"flower{}.png\".format(round(time.time())))\n",
        "    plt.close()\n",
        "def generate_gif(frames=400, filename=\"evolution\"):\n",
        "    # Make a GIF of the current generator outputting images with a moving perlin noise\n",
        "    anim_file = \"{}{}.gif\".format(filename, round(time.time()))\n",
        "    perlin = (tf.random.uniform(shape=[1, noise_dim], minval=0.3, maxval=0.7))#(tf.ones([1, noise_dim]))\n",
        "    with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "        for i in range(frames):\n",
        "            # Make image\n",
        "            array_image = np.array(tf.cast(tf.math.round(generator(perlin, training=False)[:, :, :] * 127.5 + 127.5), tf.uint8)[0, :, :, :])\n",
        "\n",
        "            # Put image in writer for gif\n",
        "            writer.append_data(array_image)\n",
        "            # Change 1 bit, half at a time(so loop gif is 4times the noise worth of frames\n",
        "\n",
        "            array = np.array(perlin)\n",
        "            index = i % noise_dim\n",
        "            #array[0][index] = (0.5 if int(array[0][index]) == 0.25 else (0.75 if int(array[0][index]) == 0.5 else (0.51 if int(array[0][index]) == 0.75 else 0.25)))\n",
        "            randbit = (random.uniform(0.8,0.9) if random.choice([0,1])==1 else random.uniform(1.1,1.2))\n",
        "            array[0][index] = array[0][index]*randbit\n",
        "            perlin = tf.cast(array, tf.float32)\n",
        "            if i % (frames / 5) == 0: print(\"{} % complete\".format(i*100//frames))\n",
        "        print(\"Finished. File called: {}\".format(anim_file))\n",
        "\n",
        "def getDataAndCache(dir='/birds', max=200, type='.jpg'):\n",
        "\n",
        "\n",
        "\n",
        "    # Load Image Directory\n",
        "    data_dir = pathlib.Path(str(dir))\n",
        "    image_count = len(list(data_dir.glob('*/*'+type)))\n",
        "    print(\"{} images in the set.\".format(image_count))\n",
        "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        data_dir,\n",
        "        seed=123,\n",
        "        image_size=(img_height, img_width),\n",
        "        labels=None,\n",
        "        batch_size=min(max,image_count-image_count%BATCH_SIZE))\n",
        "\n",
        "    image_batch = next(iter(train_ds))\n",
        "\n",
        "    # Prepare data\n",
        "    train_images = (image_batch - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
        "\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "    print(\"With {} batches of {} images each.\".format(len(train_dataset), BATCH_SIZE))\n",
        "    # .cache keeps images in memory during training.\n",
        "    train_dataset = train_dataset.cache()\n",
        "    return train_dataset\n",
        "\n",
        "def production(preschool = 2, rate = 2, produce=1, time_allowed=60, gif=True, image=True):\n",
        "    start = time.time()\n",
        "\n",
        "# early training period to get it up to scratch\n",
        "    print(\"Starting preschool for {} epochs\".format(preschool))\n",
        "    train(train_dataset, preschool)\n",
        "\n",
        "\n",
        "# Production period, pump out the gifs and photos\n",
        "    for i in range(produce):\n",
        "        if time.time()-start<time_allowed:\n",
        "            print(\"Production lot {} starting. Training for {} epochs.\".format(i+1,rate))\n",
        "            train(train_dataset, rate)\n",
        "\n",
        "            if gif: generate_gif()\n",
        "            if image: generate_image()\n",
        "\n",
        "            print(\"Production lot {} finished.\".format(i+1))\n",
        "        else:\n",
        "            print(\"Finished due to time constraints.\")\n",
        "            break\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "\n",
        "__all__ = [\n",
        "    'acgan_discriminator_loss',\n",
        "    'acgan_generator_loss',\n",
        "    'least_squares_discriminator_loss',\n",
        "    'least_squares_generator_loss',\n",
        "    'modified_discriminator_loss',\n",
        "    'modified_generator_loss',\n",
        "    'minimax_discriminator_loss',\n",
        "    'minimax_generator_loss',\n",
        "    'wasserstein_discriminator_loss',\n",
        "    'wasserstein_hinge_generator_loss',\n",
        "    'wasserstein_hinge_discriminator_loss',\n",
        "    'wasserstein_generator_loss',\n",
        "    'wasserstein_gradient_penalty',\n",
        "    'mutual_information_penalty',\n",
        "    'combine_adversarial_loss',\n",
        "    'cycle_consistency_loss',\n",
        "]\n",
        "\n",
        "\n",
        "def _to_float(tensor):\n",
        "  return tf.cast(tensor, tf.float32)\n",
        "\n",
        "\n",
        "# Wasserstein losses from `Wasserstein GAN` (https://arxiv.org/abs/1701.07875).\n",
        "def wasserstein_generator_loss(\n",
        "    discriminator_gen_outputs,\n",
        "    weights=1.0,\n",
        "    scope=None,\n",
        "    loss_collection=tf.compat.v1.GraphKeys.LOSSES,\n",
        "    reduction=tf.compat.v1.losses.Reduction.SUM_BY_NONZERO_WEIGHTS,\n",
        "    add_summaries=False):\n",
        "\n",
        "  with tf.compat.v1.name_scope(scope, 'generator_wasserstein_loss',\n",
        "                               (discriminator_gen_outputs, weights)) as scope:\n",
        "    discriminator_gen_outputs = _to_float(discriminator_gen_outputs)\n",
        "\n",
        "    loss = - discriminator_gen_outputs\n",
        "    loss = tf.compat.v1.losses.compute_weighted_loss(loss, weights, scope,\n",
        "                                                     loss_collection, reduction)\n",
        "\n",
        "    if add_summaries:\n",
        "      tf.compat.v1.summary.scalar('generator_wass_loss', loss)\n",
        "\n",
        "  return loss\n",
        "\n",
        "\n",
        "def wasserstein_discriminator_loss(\n",
        "    discriminator_real_outputs,\n",
        "    discriminator_gen_outputs,\n",
        "    real_weights=1.0,\n",
        "    generated_weights=1.0,\n",
        "    scope=None,\n",
        "    loss_collection=tf.compat.v1.GraphKeys.LOSSES,\n",
        "    reduction=tf.compat.v1.losses.Reduction.SUM_BY_NONZERO_WEIGHTS,\n",
        "    add_summaries=False):\n",
        "  with tf.compat.v1.name_scope(\n",
        "      scope, 'discriminator_wasserstein_loss',\n",
        "      (discriminator_real_outputs, discriminator_gen_outputs, real_weights,\n",
        "       generated_weights)) as scope:\n",
        "    discriminator_real_outputs = _to_float(discriminator_real_outputs)\n",
        "    discriminator_gen_outputs = _to_float(discriminator_gen_outputs)\n",
        "    discriminator_real_outputs.shape.assert_is_compatible_with(\n",
        "        discriminator_gen_outputs.shape)\n",
        "\n",
        "    loss_on_generated = tf.compat.v1.losses.compute_weighted_loss(\n",
        "        discriminator_gen_outputs,\n",
        "        generated_weights,\n",
        "        scope,\n",
        "        loss_collection=None,\n",
        "        reduction=reduction)\n",
        "    loss_on_real = tf.compat.v1.losses.compute_weighted_loss(\n",
        "        discriminator_real_outputs,\n",
        "        real_weights,\n",
        "        scope,\n",
        "        loss_collection=None,\n",
        "        reduction=reduction)\n",
        "    loss = loss_on_generated - loss_on_real\n",
        "    tf.compat.v1.losses.add_loss(loss, loss_collection)\n",
        "\n",
        "    if add_summaries:\n",
        "      tf.compat.v1.summary.scalar('discriminator_gen_wass_loss',\n",
        "                                  loss_on_generated)\n",
        "      tf.compat.v1.summary.scalar('discriminator_real_wass_loss', loss_on_real)\n",
        "      tf.compat.v1.summary.scalar('discriminator_wass_loss', loss)\n",
        "\n",
        "  return loss\n",
        "\n",
        "\n",
        "wasserstein_hinge_generator_loss = wasserstein_generator_loss\n",
        "wasserstein_hinge_generator_loss.__name__ = 'wasserstein_hinge_generator_loss'\n",
        "\n",
        "\n",
        "def wasserstein_hinge_discriminator_loss(\n",
        "    discriminator_real_outputs,\n",
        "    discriminator_gen_outputs,\n",
        "    real_weights=1.0,\n",
        "    generated_weights=1.0,\n",
        "    real_hinge=1.0,\n",
        "    generated_hinge=1.0,\n",
        "    scope=None,\n",
        "    loss_collection=tf.compat.v1.GraphKeys.LOSSES,\n",
        "    reduction=tf.compat.v1.losses.Reduction.SUM_BY_NONZERO_WEIGHTS,\n",
        "    add_summaries=False):\n",
        "\n",
        "  with tf.compat.v1.name_scope(\n",
        "      scope, 'discriminator_wasserstein_hinge_loss',\n",
        "      (discriminator_real_outputs, discriminator_gen_outputs, real_weights,\n",
        "       generated_weights)) as scope:\n",
        "    discriminator_real_outputs = _to_float(discriminator_real_outputs)\n",
        "    discriminator_gen_outputs = _to_float(discriminator_gen_outputs)\n",
        "    discriminator_real_outputs.shape.assert_is_compatible_with(\n",
        "        discriminator_gen_outputs.shape)\n",
        "\n",
        "    # Compute the hinge.\n",
        "    hinged_real = tf.nn.relu(real_hinge - discriminator_real_outputs)\n",
        "    hinged_gen = tf.nn.relu(generated_hinge + discriminator_gen_outputs)\n",
        "\n",
        "    # Average.\n",
        "    loss_on_real = tf.compat.v1.losses.compute_weighted_loss(\n",
        "        hinged_real,\n",
        "        real_weights,\n",
        "        scope,\n",
        "        loss_collection=None,\n",
        "        reduction=reduction)\n",
        "    loss_on_generated = tf.compat.v1.losses.compute_weighted_loss(\n",
        "        hinged_gen,\n",
        "        generated_weights,\n",
        "        scope,\n",
        "        loss_collection=None,\n",
        "        reduction=reduction)\n",
        "    loss = loss_on_generated + loss_on_real\n",
        "    tf.compat.v1.losses.add_loss(loss, loss_collection)\n",
        "\n",
        "    if add_summaries:\n",
        "      tf.compat.v1.summary.scalar('discriminator_gen_wass_hinge_loss',\n",
        "                                  loss_on_generated)\n",
        "      tf.compat.v1.summary.scalar('discriminator_real_wass_hinge_loss',\n",
        "                                  loss_on_real)\n",
        "      tf.compat.v1.summary.scalar('discriminator_wass_hinge_loss', loss)\n",
        "\n",
        "  return loss\n",
        "\n",
        "\n",
        "# ACGAN losses from `Conditional Image Synthesis With Auxiliary Classifier GANs`\n",
        "# (https://arxiv.org/abs/1610.09585).\n",
        "def acgan_discriminator_loss(\n",
        "    discriminator_real_classification_logits,\n",
        "    discriminator_gen_classification_logits,\n",
        "    one_hot_labels,\n",
        "    label_smoothing=0.0,\n",
        "    real_weights=1.0,\n",
        "    generated_weights=1.0,\n",
        "    scope=None,\n",
        "    loss_collection=tf.compat.v1.GraphKeys.LOSSES,\n",
        "    reduction=tf.compat.v1.losses.Reduction.SUM_BY_NONZERO_WEIGHTS,\n",
        "    add_summaries=False):\n",
        "  \n",
        "  with tf.compat.v1.name_scope(\n",
        "      scope, 'acgan_discriminator_loss',\n",
        "      (discriminator_real_classification_logits,\n",
        "       discriminator_gen_classification_logits, one_hot_labels)) as scope:\n",
        "    loss_on_generated = tf.compat.v1.losses.softmax_cross_entropy(\n",
        "        one_hot_labels,\n",
        "        discriminator_gen_classification_logits,\n",
        "        weights=generated_weights,\n",
        "        scope=scope,\n",
        "        loss_collection=None,\n",
        "        reduction=reduction)\n",
        "    loss_on_real = tf.compat.v1.losses.softmax_cross_entropy(\n",
        "        one_hot_labels,\n",
        "        discriminator_real_classification_logits,\n",
        "        weights=real_weights,\n",
        "        label_smoothing=label_smoothing,\n",
        "        scope=scope,\n",
        "        loss_collection=None,\n",
        "        reduction=reduction)\n",
        "    loss = loss_on_generated + loss_on_real\n",
        "    tf.compat.v1.losses.add_loss(loss, loss_collection)\n",
        "\n",
        "    if add_summaries:\n",
        "      tf.compat.v1.summary.scalar('discriminator_gen_ac_loss',\n",
        "                                  loss_on_generated)\n",
        "      tf.compat.v1.summary.scalar('discriminator_real_ac_loss', loss_on_real)\n",
        "      tf.compat.v1.summary.scalar('discriminator_ac_loss', loss)\n",
        "\n",
        "  return loss\n",
        "\n",
        "\n",
        "def acgan_generator_loss(\n",
        "    discriminator_gen_classification_logits,\n",
        "    one_hot_labels,\n",
        "    weights=1.0,\n",
        "    scope=None,\n",
        "    loss_collection=tf.compat.v1.GraphKeys.LOSSES,\n",
        "    reduction=tf.compat.v1.losses.Reduction.SUM_BY_NONZERO_WEIGHTS,\n",
        "    add_summaries=False):\n",
        "  \n",
        "  with tf.compat.v1.name_scope(\n",
        "      scope, 'acgan_generator_loss',\n",
        "      (discriminator_gen_classification_logits, one_hot_labels)) as scope:\n",
        "    loss = tf.compat.v1.losses.softmax_cross_entropy(\n",
        "        one_hot_labels,\n",
        "        discriminator_gen_classification_logits,\n",
        "        weights=weights,\n",
        "        scope=scope,\n",
        "        loss_collection=loss_collection,\n",
        "        reduction=reduction)\n",
        "\n",
        "    if add_summaries:\n",
        "      tf.compat.v1.summary.scalar('generator_ac_loss', loss)\n",
        "\n",
        "  return loss\n",
        "\n",
        "\n",
        "\n",
        "def wasserstein_gradient_penalty(\n",
        "    real_data,\n",
        "    generated_data,\n",
        "    generator_inputs,\n",
        "    discriminator_fn,\n",
        "    discriminator_scope,\n",
        "    epsilon=1e-10,\n",
        "    target=1.0,\n",
        "    one_sided=False,\n",
        "    weights=1.0,\n",
        "    scope=None,\n",
        "    loss_collection=tf.compat.v1.GraphKeys.LOSSES,\n",
        "    reduction=tf.compat.v1.losses.Reduction.SUM_BY_NONZERO_WEIGHTS,\n",
        "    add_summaries=False):\n",
        "\n",
        "  if tf.executing_eagerly():\n",
        "    raise RuntimeError('Can\\'t use `tf.gradient` when executing eagerly.')\n",
        "  with tf.compat.v1.name_scope(scope, 'wasserstein_gradient_penalty',\n",
        "                               (real_data, generated_data)) as scope:\n",
        "    real_data = tf.convert_to_tensor(value=real_data)\n",
        "    generated_data = tf.convert_to_tensor(value=generated_data)\n",
        "    if real_data.shape.ndims is None:\n",
        "      raise ValueError('`real_data` can\\'t have unknown rank.')\n",
        "    if generated_data.shape.ndims is None:\n",
        "      raise ValueError('`generated_data` can\\'t have unknown rank.')\n",
        "\n",
        "    differences = generated_data - real_data\n",
        "    batch_size = (tf.compat.dimension_value(differences.shape.dims[0]) or\n",
        "                  tf.shape(input=differences)[0])\n",
        "    alpha_shape = [batch_size] + [1] * (differences.shape.ndims - 1)\n",
        "    alpha = tf.random.uniform(shape=alpha_shape)\n",
        "    interpolates = real_data + (alpha * differences)\n",
        "\n",
        "    with tf.compat.v1.name_scope(\n",
        "        ''):  # Clear scope so update ops are added properly.\n",
        "      # Reuse variables if variables already exists.\n",
        "      with tf.compat.v1.variable_scope(\n",
        "          discriminator_scope, 'gpenalty_dscope',\n",
        "          reuse=tf.compat.v1.AUTO_REUSE):\n",
        "        disc_interpolates = discriminator_fn(interpolates, generator_inputs)\n",
        "\n",
        "    if isinstance(disc_interpolates, tuple):\n",
        "      # ACGAN case: disc outputs more than one tensor\n",
        "      disc_interpolates = disc_interpolates[0]\n",
        "\n",
        "    gradients = tf.gradients(ys=disc_interpolates, xs=interpolates)[0]\n",
        "    gradient_squares = tf.reduce_sum(\n",
        "        input_tensor=tf.square(gradients),\n",
        "        axis=list(range(1, gradients.shape.ndims)))\n",
        "    # Propagate shape information, if possible.\n",
        "    if isinstance(batch_size, int):\n",
        "      gradient_squares.set_shape([\n",
        "          batch_size] + gradient_squares.shape.as_list()[1:])\n",
        "    # For numerical stability, add epsilon to the sum before taking the square\n",
        "    # root. Note tf.norm does not add epsilon.\n",
        "    slopes = tf.sqrt(gradient_squares + epsilon)\n",
        "    penalties = slopes / target - 1.0\n",
        "    if one_sided:\n",
        "      penalties = tf.maximum(0., penalties)\n",
        "    penalties_squared = tf.square(penalties)\n",
        "    penalty = tf.compat.v1.losses.compute_weighted_loss(\n",
        "        penalties_squared,\n",
        "        weights,\n",
        "        scope=scope,\n",
        "        loss_collection=loss_collection,\n",
        "        reduction=reduction)\n",
        "\n",
        "    if add_summaries:\n",
        "      tf.compat.v1.summary.scalar('gradient_penalty_loss', penalty)\n",
        "\n",
        "    return penalty\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def minimax_discriminator_loss(\n",
        "    discriminator_real_outputs,\n",
        "    discriminator_gen_outputs,\n",
        "    label_smoothing=0.25,\n",
        "    real_weights=1.0,\n",
        "    generated_weights=1.0,\n",
        "    scope=None,\n",
        "    loss_collection=tf.compat.v1.GraphKeys.LOSSES,\n",
        "    reduction=tf.compat.v1.losses.Reduction.SUM_BY_NONZERO_WEIGHTS,\n",
        "    add_summaries=False):\n",
        "\n",
        "  with tf.compat.v1.name_scope(\n",
        "      scope, 'discriminator_minimax_loss',\n",
        "      (discriminator_real_outputs, discriminator_gen_outputs, real_weights,\n",
        "       generated_weights, label_smoothing)) as scope:\n",
        "\n",
        "    # -log((1 - label_smoothing) - sigmoid(D(x)))\n",
        "    loss_on_real = tf.compat.v1.losses.sigmoid_cross_entropy(\n",
        "        tf.ones_like(discriminator_real_outputs),\n",
        "        discriminator_real_outputs,\n",
        "        real_weights,\n",
        "        label_smoothing,\n",
        "        scope,\n",
        "        loss_collection=None,\n",
        "        reduction=reduction)\n",
        "    # -log(- sigmoid(D(G(x))))\n",
        "    loss_on_generated = tf.compat.v1.losses.sigmoid_cross_entropy(\n",
        "        tf.zeros_like(discriminator_gen_outputs),\n",
        "        discriminator_gen_outputs,\n",
        "        generated_weights,\n",
        "        scope=scope,\n",
        "        loss_collection=None,\n",
        "        reduction=reduction)\n",
        "\n",
        "    loss = loss_on_real + loss_on_generated\n",
        "    tf.compat.v1.losses.add_loss(loss, loss_collection)\n",
        "\n",
        "    if add_summaries:\n",
        "      tf.compat.v1.summary.scalar('discriminator_gen_minimax_loss',\n",
        "                                  loss_on_generated)\n",
        "      tf.compat.v1.summary.scalar('discriminator_real_minimax_loss',\n",
        "                                  loss_on_real)\n",
        "      tf.compat.v1.summary.scalar('discriminator_minimax_loss', loss)\n",
        "\n",
        "  return loss\n",
        "\n",
        "\n",
        "def minimax_generator_loss(\n",
        "    discriminator_gen_outputs,\n",
        "    label_smoothing=0.0,\n",
        "    weights=1.0,\n",
        "    scope=None,\n",
        "    loss_collection=tf.compat.v1.GraphKeys.LOSSES,\n",
        "    reduction=tf.compat.v1.losses.Reduction.SUM_BY_NONZERO_WEIGHTS,\n",
        "    add_summaries=False):\n",
        "\n",
        "  with tf.compat.v1.name_scope(scope, 'generator_minimax_loss') as scope:\n",
        "    loss = - minimax_discriminator_loss(\n",
        "        tf.ones_like(discriminator_gen_outputs),\n",
        "        discriminator_gen_outputs, label_smoothing, weights, weights, scope,\n",
        "        loss_collection, reduction, add_summaries=False)\n",
        "\n",
        "  if add_summaries:\n",
        "    tf.compat.v1.summary.scalar('generator_minimax_loss', loss)\n",
        "\n",
        "  return loss\n",
        "\n",
        "\n",
        "def modified_discriminator_loss(\n",
        "    discriminator_real_outputs,\n",
        "    discriminator_gen_outputs,\n",
        "    label_smoothing=0.25,\n",
        "    real_weights=1.0,\n",
        "    generated_weights=1.0,\n",
        "    scope=None,\n",
        "    loss_collection=tf.compat.v1.GraphKeys.LOSSES,\n",
        "    reduction=tf.compat.v1.losses.Reduction.SUM_BY_NONZERO_WEIGHTS,\n",
        "    add_summaries=False):\n",
        "\n",
        "  return minimax_discriminator_loss(\n",
        "      discriminator_real_outputs,\n",
        "      discriminator_gen_outputs,\n",
        "      label_smoothing,\n",
        "      real_weights,\n",
        "      generated_weights,\n",
        "      scope or 'discriminator_modified_loss',\n",
        "      loss_collection,\n",
        "      reduction,\n",
        "      add_summaries)\n",
        "\n",
        "\n",
        "def modified_generator_loss(\n",
        "    discriminator_gen_outputs,\n",
        "    label_smoothing=0.0,\n",
        "    weights=1.0,\n",
        "    scope=None,\n",
        "    loss_collection=tf.compat.v1.GraphKeys.LOSSES,\n",
        "    reduction=tf.compat.v1.losses.Reduction.SUM_BY_NONZERO_WEIGHTS,\n",
        "    add_summaries=False):\n",
        "\n",
        "\n",
        "  with tf.compat.v1.name_scope(scope, 'generator_modified_loss',\n",
        "                               [discriminator_gen_outputs]) as scope:\n",
        "    loss = tf.compat.v1.losses.sigmoid_cross_entropy(\n",
        "        tf.ones_like(discriminator_gen_outputs), discriminator_gen_outputs,\n",
        "        weights, label_smoothing, scope, loss_collection, reduction)\n",
        "\n",
        "    if add_summaries:\n",
        "      tf.compat.v1.summary.scalar('generator_modified_loss', loss)\n",
        "\n",
        "  return loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def least_squares_generator_loss(\n",
        "    discriminator_gen_outputs,\n",
        "    real_label=1,\n",
        "    weights=1.0,\n",
        "    scope=None,\n",
        "    loss_collection=tf.compat.v1.GraphKeys.LOSSES,\n",
        "    reduction=tf.compat.v1.losses.Reduction.SUM_BY_NONZERO_WEIGHTS,\n",
        "    add_summaries=False):\n",
        "\n",
        "  with tf.compat.v1.name_scope(\n",
        "      scope, 'lsq_generator_loss',\n",
        "      (discriminator_gen_outputs, real_label)) as scope:\n",
        "    discriminator_gen_outputs = _to_float(discriminator_gen_outputs)\n",
        "    loss = tf.math.squared_difference(discriminator_gen_outputs,\n",
        "                                      real_label) / 2.0\n",
        "    loss = tf.compat.v1.losses.compute_weighted_loss(loss, weights, scope,\n",
        "                                                     loss_collection, reduction)\n",
        "\n",
        "  if add_summaries:\n",
        "    tf.compat.v1.summary.scalar('generator_lsq_loss', loss)\n",
        "\n",
        "  return loss\n",
        "\n",
        "\n",
        "def least_squares_discriminator_loss(\n",
        "    discriminator_real_outputs,\n",
        "    discriminator_gen_outputs,\n",
        "    real_label=1,\n",
        "    fake_label=0,\n",
        "    real_weights=1.0,\n",
        "    generated_weights=1.0,\n",
        "    scope=None,\n",
        "    loss_collection=tf.compat.v1.GraphKeys.LOSSES,\n",
        "    reduction=tf.compat.v1.losses.Reduction.SUM_BY_NONZERO_WEIGHTS,\n",
        "    add_summaries=False):\n",
        "\n",
        "  with tf.compat.v1.name_scope(\n",
        "      scope, 'lsq_discriminator_loss',\n",
        "      (discriminator_gen_outputs, real_label)) as scope:\n",
        "    discriminator_real_outputs = _to_float(discriminator_real_outputs)\n",
        "    discriminator_gen_outputs = _to_float(discriminator_gen_outputs)\n",
        "    discriminator_real_outputs.shape.assert_is_compatible_with(\n",
        "        discriminator_gen_outputs.shape)\n",
        "\n",
        "    real_losses = tf.math.squared_difference(discriminator_real_outputs,\n",
        "                                             real_label) / 2.0\n",
        "    fake_losses = tf.math.squared_difference(discriminator_gen_outputs,\n",
        "                                             fake_label) / 2.0\n",
        "\n",
        "    loss_on_real = tf.compat.v1.losses.compute_weighted_loss(\n",
        "        real_losses,\n",
        "        real_weights,\n",
        "        scope,\n",
        "        loss_collection=None,\n",
        "        reduction=reduction)\n",
        "    loss_on_generated = tf.compat.v1.losses.compute_weighted_loss(\n",
        "        fake_losses,\n",
        "        generated_weights,\n",
        "        scope,\n",
        "        loss_collection=None,\n",
        "        reduction=reduction)\n",
        "\n",
        "    loss = loss_on_real + loss_on_generated\n",
        "    tf.compat.v1.losses.add_loss(loss, loss_collection)\n",
        "\n",
        "  if add_summaries:\n",
        "    tf.compat.v1.summary.scalar('discriminator_gen_lsq_loss', loss_on_generated)\n",
        "    tf.compat.v1.summary.scalar('discriminator_real_lsq_loss', loss_on_real)\n",
        "    tf.compat.v1.summary.scalar('discriminator_lsq_loss', loss)\n",
        "\n",
        "  return loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def _validate_distributions(distributions):\n",
        "  \"\"\"Check that input is a distribution.\"\"\"\n",
        "  if not isinstance(distributions, (list, tuple)):\n",
        "    raise ValueError('`distributions` must be a list or tuple. Instead, '\n",
        "                     'found %s.' % type(distributions))\n",
        "  for x in distributions:\n",
        "    if not callable(getattr(x, 'log_prob', None)):\n",
        "      raise ValueError('`distributions` must be a list of `Distributions`. '\n",
        "                       'Instead, found %s.' % type(x))\n",
        "\n",
        "\n",
        "def _validate_information_penalty_inputs(\n",
        "    structured_generator_inputs, predicted_distributions):\n",
        "  \"\"\"Validate input to `mutual_information_penalty`.\"\"\"\n",
        "  _validate_distributions(predicted_distributions)\n",
        "  if len(structured_generator_inputs) != len(predicted_distributions):\n",
        "    raise ValueError('`structured_generator_inputs` length %i must be the same '\n",
        "                     'as `predicted_distributions` length %i.' % (\n",
        "                         len(structured_generator_inputs),\n",
        "                         len(predicted_distributions)))\n",
        "\n",
        "\n",
        "def mutual_information_penalty(\n",
        "    structured_generator_inputs,\n",
        "    predicted_distributions,\n",
        "    weights=1.0,\n",
        "    scope=None,\n",
        "    loss_collection=tf.compat.v1.GraphKeys.LOSSES,\n",
        "    reduction=tf.compat.v1.losses.Reduction.SUM_BY_NONZERO_WEIGHTS,\n",
        "    add_summaries=False):\n",
        "  \n",
        "  _validate_information_penalty_inputs(\n",
        "      structured_generator_inputs, predicted_distributions)\n",
        "\n",
        "  with tf.compat.v1.name_scope(scope, 'mutual_information_loss') as scope:\n",
        "    # Calculate the negative log-likelihood of the reconstructed noise.\n",
        "    log_probs = [\n",
        "        tf.reduce_mean(input_tensor=dist.log_prob(noise)) for dist, noise in\n",
        "        zip(predicted_distributions, structured_generator_inputs)\n",
        "    ]\n",
        "    loss = -1 * tf.compat.v1.losses.compute_weighted_loss(\n",
        "        log_probs,\n",
        "        weights,\n",
        "        scope,\n",
        "        loss_collection=loss_collection,\n",
        "        reduction=reduction)\n",
        "\n",
        "    if add_summaries:\n",
        "      tf.compat.v1.summary.scalar('mutual_information_penalty', loss)\n",
        "\n",
        "  return loss\n",
        "\n",
        "\n",
        "def numerically_stable_global_norm(tensor_list):\n",
        "  if all(x is None for x in tensor_list):\n",
        "    return 0.0\n",
        "\n",
        "  list_max = tf.reduce_max(input_tensor=[\n",
        "      tf.reduce_max(input_tensor=tf.abs(x))\n",
        "      for x in tensor_list\n",
        "      if x is not None\n",
        "  ])\n",
        "  return list_max * tf.linalg.global_norm(\n",
        "      [x / list_max for x in tensor_list if x is not None])\n",
        "\n",
        "\n",
        "def _used_weight(weights_list):\n",
        "  for weight in weights_list:\n",
        "    if weight is not None:\n",
        "      return tf.get_static_value(tf.convert_to_tensor(value=weight))\n",
        "\n",
        "\n",
        "def _validate_args(weight_factor, gradient_ratio):\n",
        "  if weight_factor is None and gradient_ratio is None:\n",
        "    raise ValueError(\n",
        "        '`weight_factor` and `gradient_ratio` cannot both be `None.`')\n",
        "  if weight_factor is not None and gradient_ratio is not None:\n",
        "    raise ValueError(\n",
        "        '`weight_factor` and `gradient_ratio` cannot both be specified.')\n",
        "\n",
        "\n",
        "# TODO(joelshor): Add ability to pass in gradients, to avoid recomputing.\n",
        "def combine_adversarial_loss(main_loss,\n",
        "                             adversarial_loss,\n",
        "                             weight_factor=None,\n",
        "                             gradient_ratio=None,\n",
        "                             gradient_ratio_epsilon=1e-6,\n",
        "                             variables=None,\n",
        "                             scalar_summaries=True,\n",
        "                             gradient_summaries=True,\n",
        "                             scope=None):\n",
        " \n",
        "  _validate_args(weight_factor, gradient_ratio)\n",
        "  if variables is None:\n",
        "    variables = contrib.get_trainable_variables()\n",
        "\n",
        "  with tf.compat.v1.name_scope(\n",
        "      scope, 'adversarial_loss', values=[main_loss, adversarial_loss]):\n",
        "    # If losses are not the same shape, reduce them to both be shape [batch,].\n",
        "    if not main_loss.shape.is_compatible_with(adversarial_loss.shape):\n",
        "      if main_loss.shape[0] != adversarial_loss.shape[0]:\n",
        "        raise ValueError(\n",
        "            'main_loss and adversarial_loss must have the same sized first '\n",
        "            'dimension. Found %d and %d.' %\n",
        "            (main_loss.shape[0], adversarial_loss.shape[0]))\n",
        "      tf.compat.v1.logging.warning(\n",
        "          'Applying mean reduction per-batch-element to main and adversarial '\n",
        "          'losses to make shapes compatible. If this is undesirable, ensure '\n",
        "          'that the shapes are compatible before passing them into '\n",
        "          'combine_adversarial_loss.')\n",
        "      main_loss = tf.math.reduce_mean(\n",
        "          input_tensor=main_loss, axis=list(range(1, main_loss.shape.rank)))\n",
        "      adversarial_loss = tf.math.reduce_mean(\n",
        "          input_tensor=adversarial_loss,\n",
        "          axis=list(range(1, adversarial_loss.shape.rank)))\n",
        "\n",
        "    # Compute gradients if we will need them.\n",
        "    if gradient_summaries or gradient_ratio is not None:\n",
        "      # `tf.gradients` doesn't work in eager.\n",
        "      if tf.executing_eagerly():\n",
        "        raise RuntimeError('`tf.gradients` doesn\\'t work in eager.')\n",
        "      main_loss_grad_mag = numerically_stable_global_norm(\n",
        "          tf.gradients(ys=main_loss, xs=variables))\n",
        "      adv_loss_grad_mag = numerically_stable_global_norm(\n",
        "          tf.gradients(ys=adversarial_loss, xs=variables))\n",
        "\n",
        "    # Add summaries, if applicable.\n",
        "    if scalar_summaries:\n",
        "      tf.compat.v1.summary.scalar('main_loss',\n",
        "                                  tf.math.reduce_mean(input_tensor=main_loss))\n",
        "      tf.compat.v1.summary.scalar(\n",
        "          'adversarial_loss',\n",
        "          tf.math.reduce_mean(input_tensor=adversarial_loss))\n",
        "    if gradient_summaries:\n",
        "      tf.compat.v1.summary.scalar('main_loss_gradients', main_loss_grad_mag)\n",
        "      tf.compat.v1.summary.scalar('adversarial_loss_gradients',\n",
        "                                  adv_loss_grad_mag)\n",
        "\n",
        "    # Combine losses in the appropriate way.\n",
        "    # If `weight_factor` is always `0`, avoid computing the adversarial loss\n",
        "    # tensor entirely.\n",
        "    if _used_weight((weight_factor, gradient_ratio)) == 0:\n",
        "      final_loss = main_loss\n",
        "    elif weight_factor is not None:\n",
        "      final_loss = (main_loss +\n",
        "                    tf.stop_gradient(weight_factor) * adversarial_loss)\n",
        "    elif gradient_ratio is not None:\n",
        "      grad_mag_ratio = main_loss_grad_mag / (\n",
        "          adv_loss_grad_mag + gradient_ratio_epsilon)\n",
        "      adv_coeff = grad_mag_ratio / gradient_ratio\n",
        "      tf.compat.v1.summary.scalar('adversarial_coefficient', adv_coeff)\n",
        "      final_loss = (main_loss +\n",
        "                    tf.stop_gradient(adv_coeff) * adversarial_loss)\n",
        "\n",
        "  return final_loss\n",
        "\n",
        "\n",
        "def cycle_consistency_loss(data_x,\n",
        "                           reconstructed_data_x,\n",
        "                           data_y,\n",
        "                           reconstructed_data_y,\n",
        "                           scope=None,\n",
        "                           add_summaries=False):\n",
        "  \n",
        "\n",
        "  with tf.compat.v1.name_scope(\n",
        "      scope,\n",
        "      'cycle_consistency_loss',\n",
        "      values=[data_x, reconstructed_data_x, data_y, reconstructed_data_y]):\n",
        "    loss_x2x = tf.compat.v1.losses.absolute_difference(data_x,\n",
        "                                                       reconstructed_data_x)\n",
        "    loss_y2y = tf.compat.v1.losses.absolute_difference(data_y,\n",
        "                                                       reconstructed_data_y)\n",
        "    loss = (loss_x2x + loss_y2y) / 2.0\n",
        "    if add_summaries:\n",
        "      tf.compat.v1.summary.scalar('cycle_consistency_loss_x2x', loss_x2x)\n",
        "      tf.compat.v1.summary.scalar('cycle_consistency_loss_y2y', loss_y2y)\n",
        "      tf.compat.v1.summary.scalar('cycle_consistency_loss', loss)\n",
        "\n",
        "  return loss\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Odt14u3qaT_b"
      },
      "source": [
        "# Define Variables\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "noise_dim = 100\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE=10\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuqAacd1aWk1",
        "outputId": "f12dbcf4-84a2-427c-fc2d-c6dd726764f7"
      },
      "source": [
        "# Check GPU\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 7859664435960541848\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 11345264640\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 7202496017301362447\n",
            "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KimHkedHmOYY",
        "outputId": "2a0e4623-51b4-4bd8-966d-1e1f1a139d77"
      },
      "source": [
        "# Create and Cache training dataset\n",
        "train_dataset = getDataAndCache(dir='birds')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "119 images in the set.\n",
            "Found 119 files belonging to 1 classes.\n",
            "With 11 batches of 10 images each.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKgVUj_VmOSg"
      },
      "source": [
        "\n",
        "# Create the Models\n",
        "generator = make_generator_model(noise_dim, img_width, img_height)\n",
        "discriminator = make_discriminator_model(img_width, img_height)\n",
        "\n",
        "# Create learning Optimisers for each model\n",
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.5)\n",
        "\n",
        "# Print summary for each model so we can see the layers n whatnot.\n",
        "generator.summary()\n",
        "discriminator.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8-4x_j3mN5U",
        "outputId": "6af46c94-96ac-4438-87bb-791a6df811d2"
      },
      "source": [
        "# Start the production process. Involves a preschool training phase where nothing is generated.\n",
        "# Then it produces 'produce' amount of sets of images, every 'rate' epochs.\n",
        "# Limit time allowed with the time_allowed variable.\n",
        "production(preschool = 100, rate = 100, produce=20, time_allowed=1*60*60, gif=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting preschool for 100 epochs\n",
            "Time for epoch 1 is 3.942 sec\n",
            "Time for epoch 2 is 4.053 sec\n",
            "Time for epoch 3 is 4.134 sec\n",
            "Time for epoch 4 is 4.136 sec\n",
            "Time for epoch 5 is 4.115 sec\n",
            "Time for epoch 6 is 4.13 sec\n",
            "Time for epoch 7 is 4.114 sec\n",
            "Time for epoch 8 is 4.122 sec\n",
            "Time for epoch 9 is 4.109 sec\n",
            "Time for epoch 10 is 4.117 sec\n",
            "Time for epoch 11 is 4.102 sec\n",
            "Time for epoch 12 is 4.105 sec\n",
            "Time for epoch 13 is 4.112 sec\n",
            "Time for epoch 14 is 4.096 sec\n",
            "Time for epoch 15 is 4.097 sec\n",
            "Time for epoch 16 is 4.1 sec\n",
            "Time for epoch 17 is 4.103 sec\n",
            "Time for epoch 18 is 4.101 sec\n",
            "Time for epoch 19 is 4.093 sec\n",
            "Time for epoch 20 is 4.093 sec\n",
            "Time for epoch 21 is 5.156 sec\n",
            "Time for epoch 22 is 3.765 sec\n",
            "Time for epoch 23 is 4.095 sec\n",
            "Time for epoch 24 is 4.084 sec\n",
            "Time for epoch 25 is 4.105 sec\n",
            "Time for epoch 26 is 4.1 sec\n",
            "Time for epoch 27 is 4.102 sec\n",
            "Time for epoch 28 is 4.094 sec\n",
            "Time for epoch 29 is 4.107 sec\n",
            "Time for epoch 30 is 4.1 sec\n",
            "Time for epoch 31 is 4.1 sec\n",
            "Time for epoch 32 is 4.102 sec\n",
            "Time for epoch 33 is 4.097 sec\n",
            "Time for epoch 34 is 4.098 sec\n",
            "Time for epoch 35 is 4.098 sec\n",
            "Time for epoch 36 is 4.082 sec\n",
            "Time for epoch 37 is 4.093 sec\n",
            "Time for epoch 38 is 4.097 sec\n",
            "Time for epoch 39 is 4.104 sec\n",
            "Time for epoch 40 is 4.092 sec\n",
            "Time for epoch 41 is 4.099 sec\n",
            "Time for epoch 42 is 4.098 sec\n",
            "Time for epoch 43 is 4.091 sec\n",
            "Time for epoch 44 is 4.095 sec\n",
            "Time for epoch 45 is 4.103 sec\n",
            "Time for epoch 46 is 4.085 sec\n",
            "Time for epoch 47 is 4.096 sec\n",
            "Time for epoch 48 is 4.094 sec\n",
            "Time for epoch 49 is 4.115 sec\n",
            "Time for epoch 50 is 4.094 sec\n",
            "Time for epoch 51 is 4.087 sec\n",
            "Time for epoch 52 is 4.092 sec\n",
            "Time for epoch 53 is 4.095 sec\n",
            "Time for epoch 54 is 4.103 sec\n",
            "Time for epoch 55 is 4.088 sec\n",
            "Time for epoch 56 is 5.154 sec\n",
            "Time for epoch 57 is 3.76 sec\n",
            "Time for epoch 58 is 4.101 sec\n",
            "Time for epoch 59 is 4.09 sec\n",
            "Time for epoch 60 is 4.078 sec\n",
            "Time for epoch 61 is 4.092 sec\n",
            "Time for epoch 62 is 4.095 sec\n",
            "Time for epoch 63 is 4.11 sec\n",
            "Time for epoch 64 is 4.102 sec\n",
            "Time for epoch 65 is 4.097 sec\n",
            "Time for epoch 66 is 4.105 sec\n",
            "Time for epoch 67 is 4.103 sec\n",
            "Time for epoch 68 is 4.111 sec\n",
            "Time for epoch 69 is 4.102 sec\n",
            "Time for epoch 70 is 4.115 sec\n",
            "Time for epoch 71 is 4.123 sec\n",
            "Time for epoch 72 is 4.098 sec\n",
            "Time for epoch 73 is 4.114 sec\n",
            "Time for epoch 74 is 4.122 sec\n",
            "Time for epoch 75 is 4.103 sec\n",
            "Time for epoch 76 is 4.122 sec\n",
            "Time for epoch 77 is 4.092 sec\n",
            "Time for epoch 78 is 4.102 sec\n",
            "Time for epoch 79 is 4.118 sec\n",
            "Time for epoch 80 is 4.1 sec\n",
            "Time for epoch 81 is 4.107 sec\n",
            "Time for epoch 82 is 4.103 sec\n",
            "Time for epoch 83 is 4.089 sec\n",
            "Time for epoch 84 is 4.119 sec\n",
            "Time for epoch 85 is 4.106 sec\n",
            "Time for epoch 86 is 4.097 sec\n",
            "Time for epoch 87 is 4.105 sec\n",
            "Time for epoch 88 is 4.109 sec\n",
            "Time for epoch 89 is 4.106 sec\n",
            "Time for epoch 90 is 4.116 sec\n",
            "Time for epoch 91 is 4.097 sec\n",
            "Time for epoch 92 is 4.122 sec\n",
            "Time for epoch 93 is 4.104 sec\n",
            "Time for epoch 94 is 4.089 sec\n",
            "Time for epoch 95 is 4.106 sec\n",
            "Time for epoch 96 is 4.089 sec\n",
            "Time for epoch 97 is 4.102 sec\n",
            "Time for epoch 98 is 4.111 sec\n",
            "Time for epoch 99 is 4.1 sec\n",
            "Time for epoch 100 is 4.098 sec\n",
            "Production lot 1 starting. Training for 100 epochs.\n",
            "Time for epoch 1 is 4.103 sec\n",
            "Time for epoch 2 is 4.103 sec\n",
            "Time for epoch 3 is 4.106 sec\n",
            "Time for epoch 4 is 4.107 sec\n",
            "Time for epoch 5 is 4.109 sec\n",
            "Time for epoch 6 is 4.111 sec\n",
            "Time for epoch 7 is 4.101 sec\n",
            "Time for epoch 8 is 4.107 sec\n",
            "Time for epoch 9 is 4.111 sec\n",
            "Time for epoch 10 is 4.103 sec\n",
            "Time for epoch 11 is 4.105 sec\n",
            "Time for epoch 12 is 4.096 sec\n",
            "Time for epoch 13 is 4.098 sec\n",
            "Time for epoch 14 is 4.092 sec\n",
            "Time for epoch 15 is 4.097 sec\n",
            "Time for epoch 16 is 4.103 sec\n",
            "Time for epoch 17 is 4.099 sec\n",
            "Time for epoch 18 is 4.105 sec\n",
            "Time for epoch 19 is 4.098 sec\n",
            "Time for epoch 20 is 4.1 sec\n",
            "Time for epoch 21 is 4.11 sec\n",
            "Time for epoch 22 is 4.105 sec\n",
            "Time for epoch 23 is 4.104 sec\n",
            "Time for epoch 24 is 4.089 sec\n",
            "Time for epoch 25 is 4.089 sec\n",
            "Time for epoch 26 is 4.109 sec\n",
            "Time for epoch 27 is 4.103 sec\n",
            "Time for epoch 28 is 4.116 sec\n",
            "Time for epoch 29 is 4.089 sec\n",
            "Time for epoch 30 is 4.11 sec\n",
            "Time for epoch 31 is 4.096 sec\n",
            "Time for epoch 32 is 4.111 sec\n",
            "Time for epoch 33 is 4.094 sec\n",
            "Time for epoch 34 is 4.109 sec\n",
            "Time for epoch 35 is 4.104 sec\n",
            "Time for epoch 36 is 4.098 sec\n",
            "Time for epoch 37 is 4.08 sec\n",
            "Time for epoch 38 is 4.087 sec\n",
            "Time for epoch 39 is 4.084 sec\n",
            "Time for epoch 40 is 4.082 sec\n",
            "Time for epoch 41 is 4.091 sec\n",
            "Time for epoch 42 is 4.091 sec\n",
            "Time for epoch 43 is 4.087 sec\n",
            "Time for epoch 44 is 4.078 sec\n",
            "Time for epoch 45 is 4.064 sec\n",
            "Time for epoch 46 is 4.08 sec\n",
            "Time for epoch 47 is 4.085 sec\n",
            "Time for epoch 48 is 4.084 sec\n",
            "Time for epoch 49 is 4.077 sec\n",
            "Time for epoch 50 is 4.08 sec\n",
            "Time for epoch 51 is 4.092 sec\n",
            "Time for epoch 52 is 4.082 sec\n",
            "Time for epoch 53 is 4.074 sec\n",
            "Time for epoch 54 is 4.089 sec\n",
            "Time for epoch 55 is 4.081 sec\n",
            "Time for epoch 56 is 5.159 sec\n",
            "Time for epoch 57 is 3.761 sec\n",
            "Time for epoch 58 is 4.102 sec\n",
            "Time for epoch 59 is 4.095 sec\n",
            "Time for epoch 60 is 4.087 sec\n",
            "Time for epoch 61 is 4.099 sec\n",
            "Time for epoch 62 is 4.094 sec\n",
            "Time for epoch 63 is 4.083 sec\n",
            "Time for epoch 64 is 4.102 sec\n"
          ]
        }
      ]
    }
  ]
}